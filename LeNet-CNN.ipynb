{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyOZx9n3/p7wLoPIwJhRBPmT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wicQ5EfCjvRc"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.layers import Conv2D, Dense, Input, Flatten, AveragePooling2D\n","from keras import Sequential\n","from keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yWYucO9o2Hc","executionInfo":{"status":"ok","timestamp":1726800772549,"user_tz":-330,"elapsed":417,"user":{"displayName":"Anurag Singh","userId":"07197084731957317211"}},"outputId":"616406a5-6aeb-43af-a5a9-844e60525441"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  0\n"]}]},{"cell_type":"code","source":["(X_train,y_train), (X_test, y_test) = mnist.load_data()"],"metadata":{"id":"FFF_w2yAkHC9","executionInfo":{"status":"ok","timestamp":1726800777354,"user_tz":-330,"elapsed":455,"user":{"displayName":"Anurag Singh","userId":"07197084731957317211"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4bdea6a2-4de2-420a-82b6-8bf64b37ca0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["y_train = to_categorical(y_train, num_classes=10)\n","y_test = to_categorical(y_test, num_classes=10)"],"metadata":{"id":"HOnpATvxlafc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Input(shape=(28, 28,1)))\n","model.add(Conv2D(6, kernel_size=(5,5), padding='valid', activation='tanh'))\n","model.add(AveragePooling2D(pool_size=(2,2), strides=2, padding='valid'))\n","model.add(Conv2D(16, kernel_size=(5,5), padding='valid', activation='tanh'))\n","model.add(AveragePooling2D(pool_size=(2,2), strides=2, padding='valid'))\n","\n","model.add(Flatten())\n","model.add(Dense(120, activation='tanh'))\n","model.add(Dense(84, activation='tanh'))\n","model.add(Dense(10, activation='softmax'))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhzYttwMkIdd","executionInfo":{"status":"ok","timestamp":1726800791970,"user_tz":-330,"elapsed":7591,"user":{"displayName":"Anurag Singh","userId":"07197084731957317211"}},"outputId":"f08b74e6-0708-47ae-e088-c1cfb1e8333e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 24, 24, 6)         156       \n","                                                                 \n"," average_pooling2d (Average  (None, 12, 12, 6)         0         \n"," Pooling2D)                                                      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 8, 8, 16)          2416      \n","                                                                 \n"," average_pooling2d_1 (Avera  (None, 4, 4, 16)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 120)               30840     \n","                                                                 \n"," dense_1 (Dense)             (None, 84)                10164     \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                850       \n","                                                                 \n","=================================================================\n","Total params: 44426 (173.54 KB)\n","Trainable params: 44426 (173.54 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"boz58rIgkpCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(X_train, y_train, batch_size=128, epochs=200, validation_data=(X_test, y_test), verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VucIiknilOIV","executionInfo":{"status":"ok","timestamp":1726801587581,"user_tz":-330,"elapsed":750673,"user":{"displayName":"Anurag Singh","userId":"07197084731957317211"}},"outputId":"27d140d3-c9b5-4367-8dd4-bc54024a8473"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","469/469 [==============================] - 5s 9ms/step - loss: 0.2487 - accuracy: 0.9282 - val_loss: 0.0800 - val_accuracy: 0.9762\n","Epoch 2/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0764 - accuracy: 0.9759 - val_loss: 0.0552 - val_accuracy: 0.9821\n","Epoch 3/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0559 - accuracy: 0.9822 - val_loss: 0.0462 - val_accuracy: 0.9858\n","Epoch 4/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.0408 - val_accuracy: 0.9861\n","Epoch 5/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0365 - accuracy: 0.9888 - val_loss: 0.0384 - val_accuracy: 0.9874\n","Epoch 6/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0391 - val_accuracy: 0.9876\n","Epoch 7/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0332 - val_accuracy: 0.9895\n","Epoch 8/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.0344 - val_accuracy: 0.9889\n","Epoch 9/200\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0323 - val_accuracy: 0.9900\n","Epoch 10/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0363 - val_accuracy: 0.9890\n","Epoch 11/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0356 - val_accuracy: 0.9887\n","Epoch 12/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0324 - val_accuracy: 0.9906\n","Epoch 13/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0390 - val_accuracy: 0.9883\n","Epoch 14/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0304 - val_accuracy: 0.9899\n","Epoch 15/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0342 - val_accuracy: 0.9886\n","Epoch 16/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0330 - val_accuracy: 0.9901\n","Epoch 17/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0420 - val_accuracy: 0.9891\n","Epoch 18/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0389 - val_accuracy: 0.9884\n","Epoch 19/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0371 - val_accuracy: 0.9901\n","Epoch 20/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0389 - val_accuracy: 0.9904\n","Epoch 21/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0353 - val_accuracy: 0.9909\n","Epoch 22/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0372 - val_accuracy: 0.9902\n","Epoch 23/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0467 - val_accuracy: 0.9880\n","Epoch 24/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0463 - val_accuracy: 0.9872\n","Epoch 25/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0381 - val_accuracy: 0.9905\n","Epoch 26/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0439 - val_accuracy: 0.9899\n","Epoch 27/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0379 - val_accuracy: 0.9906\n","Epoch 28/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0350 - val_accuracy: 0.9909\n","Epoch 29/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0384 - val_accuracy: 0.9906\n","Epoch 30/200\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0459 - val_accuracy: 0.9881\n","Epoch 31/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0447 - val_accuracy: 0.9886\n","Epoch 32/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0476 - val_accuracy: 0.9888\n","Epoch 33/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0456 - val_accuracy: 0.9876\n","Epoch 34/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0416 - val_accuracy: 0.9900\n","Epoch 35/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0420 - val_accuracy: 0.9906\n","Epoch 36/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0464 - val_accuracy: 0.9908\n","Epoch 37/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0385 - val_accuracy: 0.9905\n","Epoch 38/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0369 - val_accuracy: 0.9900\n","Epoch 39/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0418 - val_accuracy: 0.9904\n","Epoch 40/200\n","469/469 [==============================] - 4s 8ms/step - loss: 7.2130e-04 - accuracy: 0.9999 - val_loss: 0.0395 - val_accuracy: 0.9902\n","Epoch 41/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0518 - val_accuracy: 0.9859\n","Epoch 42/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0424 - val_accuracy: 0.9905\n","Epoch 43/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0363 - val_accuracy: 0.9911\n","Epoch 44/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0399 - val_accuracy: 0.9901\n","Epoch 45/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0476 - val_accuracy: 0.9889\n","Epoch 46/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0403 - val_accuracy: 0.9903\n","Epoch 47/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0452 - val_accuracy: 0.9898\n","Epoch 48/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.3962e-04 - accuracy: 0.9999 - val_loss: 0.0450 - val_accuracy: 0.9899\n","Epoch 49/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0445 - val_accuracy: 0.9901\n","Epoch 50/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0474 - val_accuracy: 0.9898\n","Epoch 51/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0427 - val_accuracy: 0.9903\n","Epoch 52/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0438 - val_accuracy: 0.9900\n","Epoch 53/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0425 - val_accuracy: 0.9908\n","Epoch 54/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0430 - val_accuracy: 0.9905\n","Epoch 55/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.2807e-04 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9913\n","Epoch 56/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.4219e-04 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9909\n","Epoch 57/200\n","469/469 [==============================] - 4s 8ms/step - loss: 7.9193e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9912\n","Epoch 58/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.1898e-05 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9913\n","Epoch 59/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.0699e-05 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9913\n","Epoch 60/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.1863e-05 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9912\n","Epoch 61/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.5017e-05 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9914\n","Epoch 62/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.1297e-05 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9915\n","Epoch 63/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.8482e-05 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9913\n","Epoch 64/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0450 - val_accuracy: 0.9897\n","Epoch 65/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0468 - val_accuracy: 0.9871\n","Epoch 66/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0434 - val_accuracy: 0.9905\n","Epoch 67/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.2998e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9911\n","Epoch 68/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.4963e-04 - accuracy: 0.9999 - val_loss: 0.0421 - val_accuracy: 0.9908\n","Epoch 69/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.5756e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9911\n","Epoch 70/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.5547e-05 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9911\n","Epoch 71/200\n","469/469 [==============================] - 4s 8ms/step - loss: 7.1941e-05 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9914\n","Epoch 72/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.8341e-05 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9915\n","Epoch 73/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.9158e-05 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9914\n","Epoch 74/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.0929e-05 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9909\n","Epoch 75/200\n","469/469 [==============================] - 4s 7ms/step - loss: 3.4693e-05 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9912\n","Epoch 76/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.9130e-05 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9913\n","Epoch 77/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.4211e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9917\n","Epoch 78/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.0417e-05 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9914\n","Epoch 79/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.7449e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9915\n","Epoch 80/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.4258e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9914\n","Epoch 81/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.1848e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9913\n","Epoch 82/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.8447e-06 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9918\n","Epoch 83/200\n","469/469 [==============================] - 4s 8ms/step - loss: 8.0941e-06 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9917\n","Epoch 84/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.7146e-06 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9917\n","Epoch 85/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.2869e-06 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9918\n","Epoch 86/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.4134e-06 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9916\n","Epoch 87/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.5843e-06 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9917\n","Epoch 88/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.8789e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9921\n","Epoch 89/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.3105e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9918\n","Epoch 90/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.8241e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9918\n","Epoch 91/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.5076e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9915\n","Epoch 92/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.2164e-06 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9918\n","Epoch 93/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.4249e-07 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9916\n","Epoch 94/200\n","469/469 [==============================] - 4s 8ms/step - loss: 7.5506e-07 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9920\n","Epoch 95/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0254 - accuracy: 0.9942 - val_loss: 0.0699 - val_accuracy: 0.9857\n","Epoch 96/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0628 - val_accuracy: 0.9887\n","Epoch 97/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0548 - val_accuracy: 0.9895\n","Epoch 98/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0537 - val_accuracy: 0.9900\n","Epoch 99/200\n","469/469 [==============================] - 4s 8ms/step - loss: 7.6770e-04 - accuracy: 0.9998 - val_loss: 0.0567 - val_accuracy: 0.9897\n","Epoch 100/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.5468e-04 - accuracy: 0.9999 - val_loss: 0.0541 - val_accuracy: 0.9907\n","Epoch 101/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.4091e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9908\n","Epoch 102/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.5181e-05 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9909\n","Epoch 103/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.4538e-05 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9909\n","Epoch 104/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.8505e-05 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9909\n","Epoch 105/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.4089e-05 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9908\n","Epoch 106/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.0447e-05 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9908\n","Epoch 107/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.7393e-05 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9907\n","Epoch 108/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.4844e-05 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9908\n","Epoch 109/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.2705e-05 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9910\n","Epoch 110/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0805e-05 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9910\n","Epoch 111/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.1064e-06 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9909\n","Epoch 112/200\n","469/469 [==============================] - 4s 8ms/step - loss: 7.6659e-06 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9911\n","Epoch 113/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.5386e-06 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9911\n","Epoch 114/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.4538e-06 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9910\n","Epoch 115/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.5695e-06 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9912\n","Epoch 116/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.8395e-06 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9913\n","Epoch 117/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.1977e-06 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9912\n","Epoch 118/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.6637e-06 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9912\n","Epoch 119/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.2096e-06 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 0.9916\n","Epoch 120/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.8160e-06 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9912\n","Epoch 121/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.5163e-06 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9914\n","Epoch 122/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.2281e-06 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9912\n","Epoch 123/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0151e-06 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9914\n","Epoch 124/200\n","469/469 [==============================] - 4s 8ms/step - loss: 8.2148e-07 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9915\n","Epoch 125/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.7571e-07 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9916\n","Epoch 126/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.5481e-07 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9914\n","Epoch 127/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.5039e-07 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9913\n","Epoch 128/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.6300e-07 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9915\n","Epoch 129/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.9968e-07 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9916\n","Epoch 130/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.4441e-07 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9917\n","Epoch 131/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.0213e-07 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9913\n","Epoch 132/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.5903e-07 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9914\n","Epoch 133/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.3081e-07 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9913\n","Epoch 134/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0757e-07 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9917\n","Epoch 135/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.0811e-08 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9916\n","Epoch 136/200\n","469/469 [==============================] - 4s 8ms/step - loss: 7.4208e-08 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9917\n","Epoch 137/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.0991e-08 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9919\n","Epoch 138/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.1965e-08 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9916\n","Epoch 139/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.4515e-08 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9917\n","Epoch 140/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.8276e-08 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9918\n","Epoch 141/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.3134e-08 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9918\n","Epoch 142/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.9353e-08 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9918\n","Epoch 143/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.6240e-08 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9919\n","Epoch 144/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0325 - accuracy: 0.9930 - val_loss: 0.0807 - val_accuracy: 0.9869\n","Epoch 145/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0644 - val_accuracy: 0.9886\n","Epoch 146/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0693 - val_accuracy: 0.9890\n","Epoch 147/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.1581e-04 - accuracy: 0.9997 - val_loss: 0.0716 - val_accuracy: 0.9888\n","Epoch 148/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0681 - val_accuracy: 0.9895\n","Epoch 149/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0774 - val_accuracy: 0.9873\n","Epoch 150/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1101 - val_accuracy: 0.9830\n","Epoch 151/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0637 - val_accuracy: 0.9905\n","Epoch 152/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0568 - val_accuracy: 0.9911\n","Epoch 153/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.8831e-04 - accuracy: 0.9997 - val_loss: 0.0606 - val_accuracy: 0.9910\n","Epoch 154/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0709 - val_accuracy: 0.9884\n","Epoch 155/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0713 - val_accuracy: 0.9896\n","Epoch 156/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0581 - val_accuracy: 0.9905\n","Epoch 157/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0637 - val_accuracy: 0.9898\n","Epoch 158/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0826 - val_accuracy: 0.9866\n","Epoch 159/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0683 - val_accuracy: 0.9897\n","Epoch 160/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0643 - val_accuracy: 0.9900\n","Epoch 161/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0777 - val_accuracy: 0.9878\n","Epoch 162/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0688 - val_accuracy: 0.9892\n","Epoch 163/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0574 - val_accuracy: 0.9900\n","Epoch 164/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0621 - val_accuracy: 0.9897\n","Epoch 165/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0587 - val_accuracy: 0.9899\n","Epoch 166/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0716 - val_accuracy: 0.9898\n","Epoch 167/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0693 - val_accuracy: 0.9888\n","Epoch 168/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0670 - val_accuracy: 0.9893\n","Epoch 169/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.7372e-04 - accuracy: 0.9999 - val_loss: 0.0596 - val_accuracy: 0.9907\n","Epoch 170/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.2384e-04 - accuracy: 0.9998 - val_loss: 0.0640 - val_accuracy: 0.9894\n","Epoch 171/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0719 - val_accuracy: 0.9884\n","Epoch 172/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0634 - val_accuracy: 0.9888\n","Epoch 173/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0625 - val_accuracy: 0.9898\n","Epoch 174/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0671 - val_accuracy: 0.9892\n","Epoch 175/200\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0658 - val_accuracy: 0.9893\n","Epoch 176/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.0191e-04 - accuracy: 0.9999 - val_loss: 0.0627 - val_accuracy: 0.9902\n","Epoch 177/200\n","469/469 [==============================] - 4s 8ms/step - loss: 8.2714e-05 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9907\n","Epoch 178/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.0271e-05 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9910\n","Epoch 179/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.4240e-05 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9911\n","Epoch 180/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.8407e-05 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9909\n","Epoch 181/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.5261e-05 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9909\n","Epoch 182/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.2893e-05 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9909\n","Epoch 183/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0998e-05 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9909\n","Epoch 184/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.3883e-06 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9910\n","Epoch 185/200\n","469/469 [==============================] - 4s 8ms/step - loss: 8.0895e-06 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9910\n","Epoch 186/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.9159e-06 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9911\n","Epoch 187/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.9478e-06 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9912\n","Epoch 188/200\n","469/469 [==============================] - 4s 8ms/step - loss: 5.0749e-06 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9908\n","Epoch 189/200\n","469/469 [==============================] - 4s 8ms/step - loss: 4.3304e-06 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9909\n","Epoch 190/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.6863e-06 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9910\n","Epoch 191/200\n","469/469 [==============================] - 4s 8ms/step - loss: 3.1206e-06 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9911\n","Epoch 192/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.6378e-06 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9910\n","Epoch 193/200\n","469/469 [==============================] - 4s 8ms/step - loss: 2.2120e-06 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9911\n","Epoch 194/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.8773e-06 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9910\n","Epoch 195/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.5616e-06 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9910\n","Epoch 196/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.3030e-06 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9910\n","Epoch 197/200\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0845e-06 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9912\n","Epoch 198/200\n","469/469 [==============================] - 4s 8ms/step - loss: 9.0410e-07 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9911\n","Epoch 199/200\n","469/469 [==============================] - 4s 8ms/step - loss: 7.4994e-07 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9911\n","Epoch 200/200\n","469/469 [==============================] - 4s 8ms/step - loss: 6.1341e-07 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9912\n"]}]},{"cell_type":"code","source":["X_test[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"id":"NDyPGIN8lTUT","executionInfo":{"status":"ok","timestamp":1726756033237,"user_tz":-330,"elapsed":35,"user":{"displayName":"Anurag Singh","userId":"07197084731957317211"}},"outputId":"7073bf03-ee8a-402d-ede8-3924957e7d38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 116, 125, 171,\n","        255, 255, 150,  93,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253,\n","        253, 253, 253, 218,  30,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253, 213,\n","        142, 176, 253, 253, 122,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  52, 250, 253, 210,  32,  12,\n","          0,   6, 206, 253, 140,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  77, 251, 210,  25,   0,   0,\n","          0, 122, 248, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  31,  18,   0,   0,   0,\n","          0, 209, 253, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        117, 247, 253, 198,  10,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76,\n","        247, 253, 231,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128,\n","        253, 253, 144,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 176, 246,\n","        253, 159,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 234, 253,\n","        233,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 253,\n","        141,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  78, 248, 253, 189,\n","         12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  19, 200, 253, 253, 141,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 134, 253, 253, 173,  12,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  25,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  43,  20,\n","         20,  20,  20,   5,   0,   5,  20,  20,  37, 150, 150, 150, 147,\n","         10,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253, 253, 253,\n","        253, 253, 253, 168, 143, 166, 253, 253, 253, 253, 253, 253, 253,\n","        123,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 174, 253, 253, 253, 253,\n","        253, 253, 253, 253, 253, 253, 253, 249, 247, 247, 169, 117, 117,\n","         57,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 118, 123, 123, 123,\n","        166, 253, 253, 253, 155, 123, 123,  41,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"],"text/html":["<style>\n","      .ndarray_repr .ndarray_raw_data {\n","        display: none;\n","      }\n","      .ndarray_repr.show_array .ndarray_raw_data {\n","        display: block;\n","      }\n","      .ndarray_repr.show_array .ndarray_image_preview {\n","        display: none;\n","      }\n","      </style>\n","      <div id=\"id-ccee0b06-be22-48f8-9fa3-88cfaee2388a\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 116, 125, 171,\n","        255, 255, 150,  93,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253,\n","        253, 253, 253, 218,  30,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253, 213,\n","        142, 176, 253, 253, 122,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  52, 250, 253, 210,  32,  12,\n","          0,   6, 206, 253, 140,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  77, 251, 210,  25,   0,   0,\n","          0, 122, 248, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  31,  18,   0,   0,   0,\n","          0, 209, 253, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        117, 247, 253, 198,  10,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76,\n","        247, 253, 231,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128,\n","        253, 253, 144,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 176, 246,\n","        253, 159,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 234, 253,\n","        233,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 253,\n","        141,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  78, 248, 253, 189,\n","         12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  19, 200, 253, 253, 141,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 134, 253, 253, 173,  12,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  25,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  43,  20,\n","         20,  20,  20,   5,   0,   5,  20,  20,  37, 150, 150, 150, 147,\n","         10,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253, 253, 253,\n","        253, 253, 253, 168, 143, 166, 253, 253, 253, 253, 253, 253, 253,\n","        123,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 174, 253, 253, 253, 253,\n","        253, 253, 253, 253, 253, 253, 253, 249, 247, 247, 169, 117, 117,\n","         57,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 118, 123, 123, 123,\n","        166, 253, 253, 253, 155, 123, 123,  41,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)</pre></div><script>\n","      (() => {\n","      const titles = ['show data', 'hide data'];\n","      let index = 0\n","      document.querySelector('#id-ccee0b06-be22-48f8-9fa3-88cfaee2388a button').onclick = (e) => {\n","        document.querySelector('#id-ccee0b06-be22-48f8-9fa3-88cfaee2388a').classList.toggle('show_array');\n","        index = (++index) % 2;\n","        document.querySelector('#id-ccee0b06-be22-48f8-9fa3-88cfaee2388a button').textContent = titles[index];\n","        e.preventDefault();\n","        e.stopPropagation();\n","      }\n","      })();\n","    </script>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["sample_image = X_test[1]\n","sample_image = sample_image.reshape(1, 28, 28, 1)\n","# sample_image"],"metadata":{"collapsed":true,"id":"hihEzDihq8wW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(sample_image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeldZP8irFSW","executionInfo":{"status":"ok","timestamp":1726756048009,"user_tz":-330,"elapsed":846,"user":{"displayName":"Anurag Singh","userId":"07197084731957317211"}},"outputId":"3e06d15b-dff3-4a32-e972-dbb896245290"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"]}]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"wFQA3kY6rH0K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_class = np.argmax(predictions, axis=1)\n","predicted_class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6YA8SLOrUyI","executionInfo":{"status":"ok","timestamp":1726756050689,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anurag Singh","userId":"07197084731957317211"}},"outputId":"6ce08334-8b29-4051-c4d9-08fd0936c72e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":[],"metadata":{"id":"35HBDKzorXkl"},"execution_count":null,"outputs":[]}]}